{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multimodalna Analiza Zmienności Rytmu Serca\n",
        "\n",
        "**Autorzy:** Bartłomiej Tempka, Juliusz Wasieleski \n",
        "**Data:** Czerwiec 2025\n",
        "\n",
        "## Opis projektu\n",
        "Projekt polega na wykonaniu multimodalnej analizy zmienności rytmu serca (HRV) z wykorzystaniem trzech datasetów:\n",
        "1. **Mechanocardiograms** - EKG + akcelerometria (Dataset 1)\n",
        "2. **Cardiac patients with valvular diseases** - EKG + akcelerometria + żyroskopia (Dataset 2)  \n",
        "3. **CEBSDB** - EKG + oddychanie + sejsmokardiografia (Dataset 3)\n",
        "\n",
        "## Cele:\n",
        "- Implementacja detektorów tętna dla różnych modalności\n",
        "- Analiza HRV w dziedzinie czasu, częstotliwości i nieliniowa\n",
        "- Porównanie wyników między modalnościami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importy podstawowe\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "from scipy.signal import find_peaks, butter, filtfilt\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Konfiguracja wykresów\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Eksploracja Dataset 1: Mechanocardiograms\n",
        "\n",
        "Ten dataset zawiera sygnały EKG wraz z akcelerometrią (mechanokardiografia). Sprawdźmy strukturę danych.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_mechanocardiogram(filepath):\n",
        "    \"\"\"Wczytanie danych mechanokardiogramów z pliku txt\"\"\"\n",
        "    data = {}\n",
        "    signals = []\n",
        "    \n",
        "    with open(filepath, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    \n",
        "    header_end = 0\n",
        "    for i, line in enumerate(lines):\n",
        "        if line.startswith('[DATA]'):\n",
        "            header_end = i + 1\n",
        "            break\n",
        "        elif 'Sample rate' in line:\n",
        "            data['fs'] = int(line.split('=')[1].strip().replace('Hz', ''))\n",
        "        elif 'Measurement length' in line:\n",
        "            data['duration'] = line.split(':')[1].strip()\n",
        "        elif line.startswith('Signal'):\n",
        "            signal_info = line.strip().split(': ')\n",
        "            signal_name = signal_info[1].split(',')[0]\n",
        "            signals.append(signal_name)\n",
        "    \n",
        "    # Wczytaj dane numeryczne\n",
        "    if header_end > 0:\n",
        "        numeric_data = []\n",
        "        for line in lines[header_end:]:\n",
        "            if line.strip():\n",
        "                values = [float(x) for x in line.strip().split()]\n",
        "                numeric_data.append(values)\n",
        "        \n",
        "        data['signals'] = np.array(numeric_data).T\n",
        "        data['signal_names'] = signals\n",
        "        data['time'] = np.arange(len(data['signals'][0])) / data['fs']\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Eksploracja Dataset 2: Cardiac Patients\n",
        "\n",
        "Ten dataset zawiera dane pacjentów z wadami zastawkowymi serca, rejestrowane za pomocą sensorów Shimmer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_cardiac_patient_data(filepath):\n",
        "    \"\"\"Wczytanie danych pacjentów kardiologicznych z pliku CSV Shimmer\"\"\"\n",
        "    \n",
        "    # Wczytaj plik CSV, pomijając pierwszą linię z sep=,\n",
        "    try:\n",
        "        df = pd.read_csv(filepath, skiprows=1)\n",
        "        \n",
        "        # Wyodrębnij podstawowe informacje\n",
        "        data = {}\n",
        "        \n",
        "        # POPRAWKA: Konwertuj timestamp na liczbę\n",
        "        timestamp_raw = df.iloc[:, 0].values  # Pierwsza kolumna to timestamp\n",
        "        data['timestamp'] = pd.to_numeric(timestamp_raw, errors='coerce')\n",
        "        \n",
        "        # Usuń wiersze z nieprawidłowymi timestampami (NaN)\n",
        "        valid_mask = ~np.isnan(data['timestamp'])\n",
        "        data['timestamp'] = data['timestamp'][valid_mask]\n",
        "        \n",
        "        # Identyfikuj kolumny według nazw\n",
        "        ecg_cols = [col for col in df.columns if 'ECG' in col and 'CAL' in col]\n",
        "        acc_cols = [col for col in df.columns if 'Accel' in col and 'CAL' in col]\n",
        "        gyro_cols = [col for col in df.columns if 'Gyro' in col and 'CAL' in col]\n",
        "        \n",
        "        # POPRAWKA: Konwertuj wszystkie sygnały na liczby\n",
        "        if ecg_cols:\n",
        "            ecg_raw = df[ecg_cols].values[valid_mask]\n",
        "            data['ecg'] = pd.DataFrame(ecg_raw).apply(pd.to_numeric, errors='coerce').values\n",
        "            data['ecg_names'] = ecg_cols\n",
        "        \n",
        "        if acc_cols:\n",
        "            acc_raw = df[acc_cols].values[valid_mask]\n",
        "            data['accelerometer'] = pd.DataFrame(acc_raw).apply(pd.to_numeric, errors='coerce').values\n",
        "            data['acc_names'] = acc_cols\n",
        "            \n",
        "        if gyro_cols:\n",
        "            gyro_raw = df[gyro_cols].values[valid_mask]\n",
        "            data['gyroscope'] = pd.DataFrame(gyro_raw).apply(pd.to_numeric, errors='coerce').values\n",
        "            data['gyro_names'] = gyro_cols\n",
        "        \n",
        "        # Usuń wiersze z NaN w sygnałach (jeśli występują)\n",
        "        if 'ecg' in data:\n",
        "            ecg_valid = ~np.isnan(data['ecg']).any(axis=1)\n",
        "            for key in ['timestamp', 'ecg', 'accelerometer', 'gyroscope']:\n",
        "                if key in data and key != 'timestamp':\n",
        "                    data[key] = data[key][ecg_valid]\n",
        "            if 'timestamp' in data:\n",
        "                data['timestamp'] = data['timestamp'][ecg_valid]\n",
        "        \n",
        "        # Oszacuj częstotliwość próbkowania\n",
        "        if len(data['timestamp']) > 1:\n",
        "            dt = np.median(np.diff(data['timestamp']))\n",
        "            data['fs'] = 1.0 / (dt / 1000.0)  # Convert ms to Hz\n",
        "        \n",
        "        # Czas w sekundach od początku\n",
        "        data['time'] = (data['timestamp'] - data['timestamp'][0]) / 1000.0\n",
        "        \n",
        "        print(f\"Pomyślnie wczytano {len(data['timestamp'])} próbek\")\n",
        "        \n",
        "        # Sprawdź typy danych\n",
        "        if 'ecg' in data:\n",
        "            print(f\"Typ danych EKG: {data['ecg'].dtype}\")\n",
        "        if 'accelerometer' in data:\n",
        "            print(f\"Typ danych akcelerometru: {data['accelerometer'].dtype}\")\n",
        "        if 'gyroscope' in data:\n",
        "            print(f\"Typ danych żyroskopu: {data['gyroscope'].dtype}\")\n",
        "        \n",
        "        return data\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Błąd wczytywania: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Implementacja Detektorów Tętna\n",
        "\n",
        "Implementujemy detektory dla różnych modalności:\n",
        "- **EKG**: Klasyczny detektor zespołów QRS\n",
        "- **SCG** (Sejsmokardiografia): Detektor na podstawie akcelerometru\n",
        "- **GCG** (Żyrokardiografia): Detektor na podstawie żyroskopu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HeartbeatDetector:\n",
        "    \"\"\"Klasa bazowa dla detektorów tętna\"\"\"\n",
        "    \n",
        "    def __init__(self, fs):\n",
        "        self.fs = fs\n",
        "    \n",
        "    def bandpass_filter(self, signal, low_freq, high_freq, order=4):\n",
        "        \"\"\"Filtr pasmowo-przepustowy\"\"\"\n",
        "        nyquist = self.fs / 2\n",
        "        low = low_freq / nyquist\n",
        "        high = high_freq / nyquist\n",
        "        b, a = butter(order, [low, high], btype='band')\n",
        "        return filtfilt(b, a, signal)\n",
        "    \n",
        "    def detect_peaks(self, signal, **kwargs):\n",
        "        \"\"\"Bazowa metoda detekcji pików\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ECGDetector(HeartbeatDetector):\n",
        "    \"\"\"Detektor dla sygnałów EKG - Pan-Tompkins algorithm\"\"\"\n",
        "    \n",
        "    def detect_peaks(self, ecg_signal, min_peak_height=None, min_distance=None):\n",
        "        \"\"\"Detekcja zespołów QRS w sygnale EKG\"\"\"\n",
        "        \n",
        "        # Parametry domyślne\n",
        "        if min_distance is None:\n",
        "            min_distance = int(0.6 * self.fs)  # Minimum 100 BPM\n",
        "        \n",
        "        # Krok 1: Filtracja pasmowa (5-15 Hz dla QRS)\n",
        "        filtered = self.bandpass_filter(ecg_signal, 5, 15)\n",
        "        \n",
        "        # Krok 2: Różniczkowanie\n",
        "        diff_signal = np.diff(filtered)\n",
        "        \n",
        "        # Krok 3: Podnoszenie do kwadratu\n",
        "        squared = diff_signal ** 2\n",
        "        \n",
        "        # Krok 4: Średnia ruchoma\n",
        "        window_size = int(0.15 * self.fs)  # 150ms window\n",
        "        integrated = np.convolve(squared, np.ones(window_size)/window_size, mode='same')\n",
        "        \n",
        "        # Krok 5: Detekcja pików\n",
        "        if min_peak_height is None:\n",
        "            min_peak_height = 0.35 * np.max(integrated)\n",
        "        \n",
        "        peaks, _ = find_peaks(integrated, \n",
        "                            height=min_peak_height,\n",
        "                            distance=min_distance)\n",
        "        \n",
        "        return peaks\n",
        "\n",
        "class SCGDetector(HeartbeatDetector):\n",
        "    \"\"\"Detektor dla sejsmokardiogramów (akcelerometr)\"\"\"\n",
        "    \n",
        "    def detect_peaks(self, acc_signal, axis=2, min_peak_height=None, min_distance=None):\n",
        "        \"\"\"Detekcja uderzeń serca z sygnału akcelerometru\"\"\"\n",
        "        \n",
        "        if min_distance is None:\n",
        "            min_distance = int(0.4 * self.fs)  # Minimum 150 BPM\n",
        "        \n",
        "        # Wybierz odpowiednią oś lub oblicz magnitude\n",
        "        if acc_signal.ndim == 1:\n",
        "            signal_to_process = acc_signal\n",
        "        else:\n",
        "            if axis is None:\n",
        "                # Magnitude wszystkich osi\n",
        "                signal_to_process = np.sqrt(np.sum(acc_signal**2, axis=1))\n",
        "            else:\n",
        "                signal_to_process = acc_signal[:, axis]\n",
        "        \n",
        "        # Filtracja dla sygnałów kardiologicznych (1-40 Hz)\n",
        "        filtered = self.bandpass_filter(signal_to_process, 1, 40)\n",
        "        \n",
        "        # Wzmocnienie przez podniesienie do kwadratu\n",
        "        enhanced = filtered ** 2\n",
        "        \n",
        "        # Wygładzenie\n",
        "        window_size = int(0.1 * self.fs)  # 100ms window\n",
        "        smoothed = np.convolve(enhanced, np.ones(window_size)/window_size, mode='same')\n",
        "        \n",
        "        # Detekcja pików\n",
        "        if min_peak_height is None:\n",
        "            min_peak_height = 0.3 * np.max(smoothed)\n",
        "        \n",
        "        peaks, _ = find_peaks(smoothed,\n",
        "                            height=min_peak_height,\n",
        "                            distance=min_distance)\n",
        "        \n",
        "        return peaks\n",
        "\n",
        "class GCGDetector(HeartbeatDetector):\n",
        "    \"\"\"Detektor dla żyrokardiogramów (żyroskop)\"\"\"\n",
        "    \n",
        "    def detect_peaks(self, gyro_signal, axis=2, min_peak_height=None, min_distance=None):\n",
        "        \"\"\"Detekcja uderzeń serca z sygnału żyroskopu\"\"\"\n",
        "        \n",
        "        if min_distance is None:\n",
        "            min_distance = int(0.4 * self.fs)  # Minimum 150 BPM\n",
        "        \n",
        "        # Wybierz odpowiednią oś lub oblicz magnitude\n",
        "        if gyro_signal.ndim == 1:\n",
        "            signal_to_process = gyro_signal\n",
        "        else:\n",
        "            if axis is None:\n",
        "                # Magnitude wszystkich osi\n",
        "                signal_to_process = np.sqrt(np.sum(gyro_signal**2, axis=1))\n",
        "            else:\n",
        "                signal_to_process = gyro_signal[:, axis]\n",
        "        \n",
        "        # Filtracja dla sygnałów kardiologicznych (1-20 Hz)\n",
        "        filtered = self.bandpass_filter(signal_to_process, 1, 20)\n",
        "        \n",
        "        # Wartość bezwzględna różniczki (wykrywa szybkie zmiany)\n",
        "        diff_signal = np.abs(np.diff(filtered))\n",
        "        diff_signal = np.append(diff_signal, diff_signal[-1])  # Restore length\n",
        "        \n",
        "        # Wygładzenie\n",
        "        window_size = int(0.08 * self.fs)  # 80ms window\n",
        "        smoothed = np.convolve(diff_signal, np.ones(window_size)/window_size, mode='same')\n",
        "        \n",
        "        # Detekcja pików\n",
        "        if min_peak_height is None:\n",
        "            min_peak_height = 0.4 * np.max(smoothed)\n",
        "        \n",
        "        peaks, _ = find_peaks(smoothed,\n",
        "                            height=min_peak_height,\n",
        "                            distance=min_distance)\n",
        "        \n",
        "        return peaks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Analiza HRV (Heart Rate Variability)\n",
        "\n",
        "Implementujemy analizę zmienności rytmu serca w trzech domenach:\n",
        "- **Dziedzina czasu**: AVNN, SDNN, RMSSD, pNN50\n",
        "- **Dziedzina częstotliwości**: VLF, LF, HF, LF/HF\n",
        "- **Analiza nieliniowa**: wykres Poincaré (SD1, SD2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HRVAnalyzer:\n",
        "    \"\"\"Klasa do analizy zmienności rytmu serca\"\"\"\n",
        "    \n",
        "    def __init__(self, rr_intervals):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            rr_intervals: odstępy RR w milisekundach\n",
        "        \"\"\"\n",
        "        self.rr_intervals = np.array(rr_intervals)\n",
        "        self.nn_intervals = self.filter_normal_intervals()  # Filtrowane odstępy NN\n",
        "    \n",
        "    def filter_normal_intervals(self, min_rr=300, max_rr=2000):\n",
        "        \"\"\"Filtracja nietypowych odstępów RR\"\"\"\n",
        "        mask = (self.rr_intervals >= min_rr) & (self.rr_intervals <= max_rr)\n",
        "        return self.rr_intervals[mask]\n",
        "    \n",
        "    def time_domain_analysis(self):\n",
        "        \"\"\"Analiza w dziedzinie czasu\"\"\"\n",
        "        if len(self.nn_intervals) < 2:\n",
        "            return {}\n",
        "        \n",
        "        # Podstawowe statystyki\n",
        "        avnn = np.mean(self.nn_intervals)  # Średni odstęp NN\n",
        "        sdnn = np.std(self.nn_intervals, ddof=1)  # Odchylenie standardowe\n",
        "        \n",
        "        # RMSSD - Root Mean Square of Successive Differences\n",
        "        diff_nn = np.diff(self.nn_intervals)\n",
        "        rmssd = np.sqrt(np.mean(diff_nn**2))\n",
        "        \n",
        "        # pNN50 - procent różnic > 50ms\n",
        "        pnn50 = (np.sum(np.abs(diff_nn) > 50) / len(diff_nn)) * 100\n",
        "        \n",
        "        # pNN20 - procent różnic > 20ms (dodatkowy wskaźnik)\n",
        "        pnn20 = (np.sum(np.abs(diff_nn) > 20) / len(diff_nn)) * 100\n",
        "        \n",
        "        return {\n",
        "            'AVNN': avnn,\n",
        "            'SDNN': sdnn,\n",
        "            'RMSSD': rmssd,\n",
        "            'pNN50': pnn50,\n",
        "            'pNN20': pnn20,\n",
        "            'HR_mean': 60000 / avnn if avnn > 0 else 0  # Średnie tętno\n",
        "        }\n",
        "    \n",
        "    def frequency_domain_analysis(self, fs_resample=4):\n",
        "        \"\"\"Analiza w dziedzinie częstotliwości\"\"\"\n",
        "        if len(self.nn_intervals) < 10:\n",
        "            return {}\n",
        "        \n",
        "        # Interpolacja do równomiernie próbkowanego sygnału\n",
        "        time_original = np.cumsum(self.nn_intervals) / 1000.0  # Convert to seconds\n",
        "        time_new = np.arange(0, time_original[-1], 1/fs_resample)\n",
        "        \n",
        "        # Interpolacja liniowa\n",
        "        rr_interpolated = np.interp(time_new, time_original, self.nn_intervals)\n",
        "        \n",
        "        # Detrending\n",
        "        rr_detrended = rr_interpolated - np.mean(rr_interpolated)\n",
        "        \n",
        "        # FFT\n",
        "        fft_vals = np.fft.fft(rr_detrended)\n",
        "        fft_freqs = np.fft.fftfreq(len(rr_detrended), 1/fs_resample)\n",
        "        \n",
        "        # Power spectral density (PSD)\n",
        "        psd = np.abs(fft_vals)**2\n",
        "        \n",
        "        # Definicje pasm częstotliwości (Hz)\n",
        "        vlf_band = (0.0033, 0.04)\n",
        "        lf_band = (0.04, 0.15)\n",
        "        hf_band = (0.15, 0.4)\n",
        "        \n",
        "        # Znajdź indeksy dla każdego pasma\n",
        "        def get_band_power(freq_range):\n",
        "            mask = (fft_freqs >= freq_range[0]) & (fft_freqs <= freq_range[1])\n",
        "            return np.sum(psd[mask]) if np.any(mask) else 0\n",
        "        \n",
        "        vlf_power = get_band_power(vlf_band)\n",
        "        lf_power = get_band_power(lf_band)\n",
        "        hf_power = get_band_power(hf_band)\n",
        "        \n",
        "        total_power = vlf_power + lf_power + hf_power\n",
        "        \n",
        "        # Znormalizowane moce\n",
        "        lf_norm = (lf_power / (lf_power + hf_power)) * 100 if (lf_power + hf_power) > 0 else 0\n",
        "        hf_norm = (hf_power / (lf_power + hf_power)) * 100 if (lf_power + hf_power) > 0 else 0\n",
        "        \n",
        "        # Stosunek LF/HF\n",
        "        lf_hf_ratio = lf_power / hf_power if hf_power > 0 else 0\n",
        "        \n",
        "        return {\n",
        "            'VLF_power': vlf_power,\n",
        "            'LF_power': lf_power,\n",
        "            'HF_power': hf_power,\n",
        "            'Total_power': total_power,\n",
        "            'LF_norm': lf_norm,\n",
        "            'HF_norm': hf_norm,\n",
        "            'LF_HF_ratio': lf_hf_ratio\n",
        "        }\n",
        "    \n",
        "    def nonlinear_analysis(self):\n",
        "        \"\"\"Analiza nieliniowa - wykres Poincaré\"\"\"\n",
        "        if len(self.nn_intervals) < 2:\n",
        "            return {}\n",
        "        \n",
        "        # Współrzędne wykresu Poincaré\n",
        "        rr_n = self.nn_intervals[:-1]\n",
        "        rr_n1 = self.nn_intervals[1:]\n",
        "        \n",
        "        # SD1 - krótkookresowa zmienność (szerokość chmury punktów)\n",
        "        diff_rr = rr_n1 - rr_n\n",
        "        sd1 = np.std(diff_rr, ddof=1) / np.sqrt(2)\n",
        "        \n",
        "        # SD2 - długookresowa zmienność (długość chmury punktów)\n",
        "        sum_rr = rr_n1 + rr_n\n",
        "        sd2 = np.std(sum_rr, ddof=1) / np.sqrt(2)\n",
        "        \n",
        "        # SD1/SD2 ratio\n",
        "        sd_ratio = sd1 / sd2 if sd2 > 0 else 0\n",
        "        \n",
        "        return {\n",
        "            'SD1': sd1,\n",
        "            'SD2': sd2,\n",
        "            'SD1_SD2_ratio': sd_ratio,\n",
        "            'poincare_rr_n': rr_n,\n",
        "            'poincare_rr_n1': rr_n1\n",
        "        }\n",
        "    \n",
        "    def comprehensive_analysis(self):\n",
        "        \"\"\"Kompletna analiza HRV\"\"\"\n",
        "        results = {}\n",
        "        results.update(self.time_domain_analysis())\n",
        "        results.update(self.frequency_domain_analysis())\n",
        "        results.update(self.nonlinear_analysis())\n",
        "        return results\n",
        "\n",
        "def peaks_to_rr_intervals(peaks, fs):\n",
        "    \"\"\"Konwersja pozycji pików na odstępy RR w milisekundach\"\"\"\n",
        "    if len(peaks) < 2:\n",
        "        return np.array([])\n",
        "    \n",
        "    rr_samples = np.diff(peaks)\n",
        "    rr_ms = (rr_samples / fs) * 1000  # Convert to milliseconds\n",
        "    return rr_ms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Przykład Analizy Multimodalnej\n",
        "\n",
        "Teraz przeprowadzimy przykładową analizę na rzeczywistych danych z obu datasetów.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pomyślnie wczytano 124838 próbek\n",
            "Typ danych EKG: float64\n",
            "Typ danych akcelerometru: float64\n",
            "Typ danych żyroskopu: float64\n",
            "=== Analiza Pacjenta CP-01 ===\n",
            "Czas nagrania: 8.1 minut\n",
            "Częstotliwość próbkowania: 256.0 Hz\n",
            "\n",
            "--- Analiza EKG ---\n",
            "Wykryto 10 zespołów QRS\n",
            "Średnie tętno: 0.0 BPM\n",
            "SDNN: 0.0 ms\n",
            "RMSSD: 0.0 ms\n",
            "LF/HF: 0.00\n",
            "\n",
            "--- Analiza Akcelerometru ---\n",
            "Wykryto 5 uderzeń serca (SCG)\n",
            "Średnie tętno: 70.1 BPM\n",
            "SDNN: 116.0 ms\n",
            "RMSSD: 164.1 ms\n",
            "LF/HF: 0.00\n",
            "\n",
            "--- Analiza Żyroskopu ---\n",
            "Nie wykryto wystarczającej liczby uderzeń serca (GCG)\n",
            "\n",
            "=== Analiza zakończona ===\n"
          ]
        }
      ],
      "source": [
        "def multimodal_analysis_example():\n",
        "    \"\"\"Przykład analizy multimodalnej dla jednego pacjenta\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Załaduj dane pacjenta\n",
        "        patient_data = load_cardiac_patient_data('Raw_Recordings/CP-01-Raw.csv')\n",
        "        \n",
        "        if patient_data is None:\n",
        "            print(\"Nie udało się załadować danych pacjenta\")\n",
        "            return\n",
        "        \n",
        "        fs = patient_data['fs']\n",
        "        duration_minutes = patient_data['time'][-1] / 60\n",
        "        \n",
        "        print(f\"=== Analiza Pacjenta CP-01 ===\")\n",
        "        print(f\"Czas nagrania: {duration_minutes:.1f} minut\")\n",
        "        print(f\"Częstotliwość próbkowania: {fs:.1f} Hz\")\n",
        "        print()\n",
        "        \n",
        "        # Wybierz fragment danych (np. pierwsze 5 minut)\n",
        "        max_samples = int(5 * 60 * fs)  # 5 minut\n",
        "        end_idx = min(max_samples, len(patient_data['time']))\n",
        "        \n",
        "        # === ANALIZA EKG ===\n",
        "        if 'ecg' in patient_data:\n",
        "            print(\"--- Analiza EKG ---\")\n",
        "            # Użyj pierwszego odprowadzenia EKG\n",
        "            ecg_signal = patient_data['ecg'][:end_idx, 0]\n",
        "            \n",
        "            # Detekcja QRS\n",
        "            ecg_detector = ECGDetector(fs)\n",
        "            qrs_peaks = ecg_detector.detect_peaks(ecg_signal)\n",
        "            \n",
        "            if len(qrs_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals = peaks_to_rr_intervals(qrs_peaks, fs)\n",
        "                hrv_analyzer = HRVAnalyzer(rr_intervals)\n",
        "                hrv_results_ecg = hrv_analyzer.comprehensive_analysis()\n",
        "                \n",
        "                print(f\"Wykryto {len(qrs_peaks)} zespołów QRS\")\n",
        "                print(f\"Średnie tętno: {hrv_results_ecg.get('HR_mean', 0):.1f} BPM\")\n",
        "                print(f\"SDNN: {hrv_results_ecg.get('SDNN', 0):.1f} ms\")\n",
        "                print(f\"RMSSD: {hrv_results_ecg.get('RMSSD', 0):.1f} ms\")\n",
        "                print(f\"LF/HF: {hrv_results_ecg.get('LF_HF_ratio', 0):.2f}\")\n",
        "            else:\n",
        "                print(\"Nie wykryto wystarczającej liczby zespołów QRS\")\n",
        "                hrv_results_ecg = {}\n",
        "\n",
        "        # === ANALIZA AKCELEROMETRU ===\n",
        "        if 'accelerometer' in patient_data:\n",
        "            print(\"\\n--- Analiza Akcelerometru ---\")\n",
        "            # Użyj osi Z akcelerometru\n",
        "            acc_signal = patient_data['accelerometer'][:end_idx, 2]  # Z-axis\n",
        "            \n",
        "            # Detekcja uderzeń serca\n",
        "            scg_detector = SCGDetector(fs)\n",
        "            scg_peaks = scg_detector.detect_peaks(acc_signal, axis=None)  # Single axis\n",
        "            \n",
        "            if len(scg_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals_scg = peaks_to_rr_intervals(scg_peaks, fs)\n",
        "                hrv_analyzer_scg = HRVAnalyzer(rr_intervals_scg)\n",
        "                hrv_results_scg = hrv_analyzer_scg.comprehensive_analysis()\n",
        "                \n",
        "                print(f\"Wykryto {len(scg_peaks)} uderzeń serca (SCG)\")\n",
        "                print(f\"Średnie tętno: {hrv_results_scg.get('HR_mean', 0):.1f} BPM\")\n",
        "                print(f\"SDNN: {hrv_results_scg.get('SDNN', 0):.1f} ms\")\n",
        "                print(f\"RMSSD: {hrv_results_scg.get('RMSSD', 0):.1f} ms\")\n",
        "                print(f\"LF/HF: {hrv_results_scg.get('LF_HF_ratio', 0):.2f}\")\n",
        "            else:\n",
        "                print(\"Nie wykryto wystarczającej liczby uderzeń serca (SCG)\")\n",
        "                hrv_results_scg = {}\n",
        "        \n",
        "        # === ANALIZA ŻYROSKOPU ===\n",
        "        if 'gyroscope' in patient_data:\n",
        "            print(\"\\n--- Analiza Żyroskopu ---\")\n",
        "            # Użyj osi Z żyroskopu\n",
        "            gyro_signal = patient_data['gyroscope'][:end_idx, 2]  # Z-axis\n",
        "            \n",
        "            # Detekcja uderzeń serca\n",
        "            gcg_detector = GCGDetector(fs)\n",
        "            gcg_peaks = gcg_detector.detect_peaks(gyro_signal, axis=None)  # Single axis\n",
        "            \n",
        "            if len(gcg_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals_gcg = peaks_to_rr_intervals(gcg_peaks, fs)\n",
        "                hrv_analyzer_gcg = HRVAnalyzer(rr_intervals_gcg)\n",
        "                hrv_results_gcg = hrv_analyzer_gcg.comprehensive_analysis()\n",
        "                \n",
        "                print(f\"Wykryto {len(gcg_peaks)} uderzeń serca (GCG)\")\n",
        "                print(f\"Średnie tętno: {hrv_results_gcg.get('HR_mean', 0):.1f} BPM\")\n",
        "                print(f\"SDNN: {hrv_results_gcg.get('SDNN', 0):.1f} ms\")\n",
        "                print(f\"RMSSD: {hrv_results_gcg.get('RMSSD', 0):.1f} ms\")\n",
        "                print(f\"LF/HF: {hrv_results_gcg.get('LF_HF_ratio', 0):.2f}\")\n",
        "            else:\n",
        "                print(\"Nie wykryto wystarczającej liczby uderzeń serca (GCG)\")\n",
        "                hrv_results_gcg = {}\n",
        "        \n",
        "        print(\"\\n=== Analiza zakończona ===\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Błąd podczas analizy: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "multimodal_analysis_example()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plan Dalszych Prac\n",
        "\n",
        "### Następne kroki dla projektu:\n",
        "\n",
        "1. **Testowanie detektorów** na większej liczbie pacjentów\n",
        "2. **Porównanie dokładności** różnych modalności\n",
        "3. **Analiza korelacji** między wynikami z różnych sygnałów\n",
        "4. **Grupowanie pacjentów** (zdrowi vs. z wadami zastawkowymi)\n",
        "5. **Walidacja** z referencyjnymi metodami\n",
        "6. **Wizualizacja wyników** - wykresy porównawcze\n",
        "7. **Analiza statystyczna** różnic między grupami\n",
        "\n",
        "### Możliwe rozszerzenia:\n",
        "- Implementacja algorytmów uczenia maszynowego dla klasyfikacji\n",
        "- Analiza w czasie rzeczywistym\n",
        "- Optymalizacja parametrów detektorów\n",
        "- Fusion różnych modalności dla lepszej dokładności\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
