{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multimodalna Analiza Zmienności Rytmu Serca\n",
        "\n",
        "**Autorzy:** Bartłomiej Tempka, Juliusz Wasieleski \n",
        "**Data:** Czerwiec 2025\n",
        "\n",
        "## Opis projektu\n",
        "Projekt polega na wykonaniu multimodalnej analizy zmienności rytmu serca (HRV) z wykorzystaniem trzech datasetów:\n",
        "1. **Mechanocardiograms** - EKG + akcelerometria (Dataset 1)\n",
        "2. **Cardiac patients with valvular diseases** - EKG + akcelerometria + żyroskopia (Dataset 2)  \n",
        "3. **CEBSDB** - EKG + oddychanie + sejsmokardiografia (Dataset 3)\n",
        "\n",
        "## Cele:\n",
        "- Implementacja detektorów tętna dla różnych modalności\n",
        "- Analiza HRV w dziedzinie czasu, częstotliwości i nieliniowa\n",
        "- Porównanie wyników między modalnościami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importy podstawowe\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "from scipy.signal import find_peaks, butter, filtfilt\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Konfiguracja wykresów\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Eksploracja Dataset 1: Mechanocardiograms\n",
        "\n",
        "Ten dataset zawiera sygnały EKG wraz z akcelerometrią (mechanokardiografia). Sprawdźmy strukturę danych.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fs': 800, 'duration': '3 min', 'time': array([0.0000000e+00, 1.2500000e-03, 2.5000000e-03, ..., 1.8335625e+02,\n",
            "       1.8335750e+02, 1.8335875e+02], shape=(146688,)), 'accX': array([6080., -712., -688., ..., -312., -344., -368.], shape=(146688,)), 'accY': array([16892., -1160., -1056., ..., -1400., -1416., -1432.],\n",
            "      shape=(146688,)), 'accZ': array([ -1704., -16448., -16432., ..., -16312., -16320., -16352.],\n",
            "      shape=(146688,)), 'gyroX': array([    0.,  1024.,  1024., ..., 19712., 19456., 19712.],\n",
            "      shape=(146688,)), 'gyroY': array([    0.,  1536.,  1792., ..., -7681., -7681., -5377.],\n",
            "      shape=(146688,)), 'gyroZ': array([   0., -256.,    0., ..., 8704., 9728., 9472.], shape=(146688,)), 'ecg': array([-436.,  446., -553., ..., -824.,  807.,  542.], shape=(146688,))}\n"
          ]
        }
      ],
      "source": [
        "def load_mechanocardiogram(filepath):\n",
        "    \"\"\"Wczytanie danych mechanokardiogramów z pliku txt\"\"\"\n",
        "    data = {}\n",
        "    signals = []\n",
        "    \n",
        "    with open(filepath, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    \n",
        "    header_end = 0\n",
        "    for i, line in enumerate(lines):\n",
        "        if line.startswith('[DATA]'):\n",
        "            header_end = i + 1\n",
        "            break\n",
        "        elif 'Sample rate' in line:\n",
        "            data['fs'] = int(line.split('=')[1].strip().replace('Hz', ''))\n",
        "        elif 'Measurement length' in line:\n",
        "            data['duration'] = line.split(':')[1].strip()\n",
        "        elif line.startswith('Signal'):\n",
        "            signal_info = line.strip().split(': ')\n",
        "            signal_name = signal_info[1].split(',')[0]\n",
        "            signals.append(signal_name)\n",
        "    \n",
        "    # Wczytaj dane numeryczne\n",
        "    if header_end > 0:\n",
        "        numeric_data = []\n",
        "        for line in lines[header_end:]:\n",
        "            if line.strip():\n",
        "                values = [float(x) for x in line.strip().split()]\n",
        "                numeric_data.append(values)\n",
        "        \n",
        "        data['signals'] = np.array(numeric_data).T\n",
        "        data['signal_names'] = signals\n",
        "        data['time'] = np.arange(len(data['signals'][0])) / data['fs']\n",
        "\n",
        "    for signal_name in signals:\n",
        "        data[signal_name] = data['signals'][signals.index(signal_name)]\n",
        "    \n",
        "    data.pop('signals', None)  # Usunięcie surowych danych sygnałów z głównego słownika\n",
        "    data.pop('signal_names', None)  # Usunięcie listy nazw sygnałów\n",
        "    if 'EKG' in data:\n",
        "        data['ecg'] = data.pop('EKG', None) \n",
        "    elif 'ECG' in data:\n",
        "        data['ecg'] = data.pop('ECG', None)\n",
        "    else:\n",
        "        raise ValueError(\"Brak danych w pliku lub nieprawidłowy format pliku.\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "print(load_mechanocardiogram('Surowe/sub_1.txt'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Eksploracja Dataset 2: Cardiac Patients\n",
        "\n",
        "Ten dataset zawiera dane pacjentów z wadami zastawkowymi serca, rejestrowane za pomocą sensorów Shimmer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_cardiac_patient_data(filepath):\n",
        "    \"\"\"Wczytanie danych pacjentów kardiologicznych z pliku CSV Shimmer\"\"\"\n",
        "    \n",
        "    # Wczytaj plik CSV, pomijając pierwszą linię z sep=,\n",
        "    #get separator from the first line\n",
        "    with open(filepath, 'r') as f:\n",
        "        first_line = f.readline().strip()\n",
        "        #remove \"\"\n",
        "        first_line = first_line.replace('\"', '')\n",
        "        if first_line.startswith('sep='):\n",
        "            skiprows = 1\n",
        "        else:\n",
        "            skiprows = 0\n",
        "        sep = first_line.split('=')[1] if '=' in first_line else ','\n",
        "    # Wczytaj dane z pliku CSV\n",
        "    df = pd.read_csv(filepath, skiprows=skiprows, sep=sep)\n",
        "    # Wyodrębnij podstawowe informacje\n",
        "    data = {}\n",
        "    \n",
        "    # POPRAWKA: Konwertuj timestamp na liczbę\n",
        "    timestamp_raw = df.iloc[:, 0].values  # Pierwsza kolumna to timestamp\n",
        "    data['timestamp'] = pd.to_numeric(timestamp_raw, errors='coerce')\n",
        "    \n",
        "    # Usuń wiersze z nieprawidłowymi timestampami (NaN)\n",
        "    valid_mask = ~np.isnan(data['timestamp'])\n",
        "    data['timestamp'] = data['timestamp'][valid_mask]\n",
        "    \n",
        "    # Identyfikuj kolumny według nazw\n",
        "    ecg_cols = [col for col in df.columns if 'ECG' in col and 'CAL' in col]\n",
        "    acc_cols = [col for col in df.columns if 'Accel' in col and 'CAL' in col]\n",
        "    gyro_cols = [col for col in df.columns if 'Gyro' in col and 'CAL' in col]\n",
        "    \n",
        "    if ecg_cols:\n",
        "        ecg_raw = df[ecg_cols].values[valid_mask]\n",
        "        data['ecg'] = pd.DataFrame(ecg_raw).apply(pd.to_numeric, errors='coerce').values\n",
        "        data['ecg_names'] = ecg_cols\n",
        "    \n",
        "    if acc_cols:\n",
        "        acc_raw = df[acc_cols].values[valid_mask]\n",
        "        data['accelerometer'] = pd.DataFrame(acc_raw).apply(pd.to_numeric, errors='coerce').values\n",
        "        data['acc_names'] = acc_cols\n",
        "        \n",
        "    if gyro_cols:\n",
        "        gyro_raw = df[gyro_cols].values[valid_mask]\n",
        "        data['gyroscope'] = pd.DataFrame(gyro_raw).apply(pd.to_numeric, errors='coerce').values\n",
        "        data['gyro_names'] = gyro_cols\n",
        "    \n",
        "    # Usuń wiersze z NaN w sygnałach (jeśli występują)\n",
        "    if 'ecg' in data:\n",
        "        data['ecg'] = data['ecg'].astype(float)\n",
        "        ecg_valid = ~np.isnan(data['ecg']).any(axis=1)\n",
        "        for key in ['timestamp', 'ecg', 'accelerometer', 'gyroscope']:\n",
        "            if key in data and key != 'timestamp':\n",
        "                data[key] = data[key][ecg_valid]\n",
        "        if 'timestamp' in data:\n",
        "            data['timestamp'] = data['timestamp'][ecg_valid]\n",
        "    \n",
        "    # Oszacuj częstotliwość próbkowania\n",
        "    if len(data['timestamp']) > 1:\n",
        "        dt = np.median(np.diff(data['timestamp']))\n",
        "        data['fs'] = 1.0 / (dt / 1000.0)  # Convert ms to Hz\n",
        "        if data['fs'] == np.inf:\n",
        "            data['fs'] = 256.0\n",
        "    \n",
        "    # Czas w sekundach od początku\n",
        "    data['time'] = (data['timestamp'] - data['timestamp'][0]) / 1000.0\n",
        "    \n",
        "    # Sprawdź typy danych\n",
        "    # if 'ecg' in data:\n",
        "    #     print(f\"Typ danych EKG: {data['ecg'].dtype}\")\n",
        "    # if 'accelerometer' in data:\n",
        "    #     print(f\"Typ danych akcelerometru: {data['accelerometer'].dtype}\")\n",
        "    # if 'gyroscope' in data:\n",
        "    #     print(f\"Typ danych żyroskopu: {data['gyroscope'].dtype}\")\n",
        "    \n",
        "\n",
        "    data['accX'] = data['accelerometer'][:, 0] if 'accelerometer' in data else None\n",
        "    data['accY'] = data['accelerometer'][:, 1] if 'accelerometer' in data else None\n",
        "    data['accZ'] = data['accelerometer'][:, 2] if 'accelerometer' in data else None\n",
        "    data['gyroX'] = data['gyroscope'][:, 0] if 'gyroscope' in data else None\n",
        "    data['gyroY'] = data['gyroscope'][:, 1] if 'gyroscope' in data else None\n",
        "    data['gyroZ'] = data['gyroscope'][:, 2] if 'gyroscope' in data else None\n",
        "    for i in range(len(data['ecg_names'])):\n",
        "        if \"LA-RA\" in data['ecg_names'][i]:\n",
        "            data['ecg'] = data['ecg'][:, i]\n",
        "    \n",
        "    # ECG_ECG_LA-RA_24BIT_CAL\n",
        "    # data['ecg'] = data['ecg'][:, 0] if 'ecg' in data else None  # Użyj tylko pierwszej kolumny EKG TODO: check bo to chyba status???\n",
        "\n",
        "    data.pop('accelerometer', None)  # Usunięcie surowych danych akcelerometru\n",
        "    data.pop('gyroscope', None)  # Usunięcie surowych danych żyroskopu\n",
        "    data.pop('acc_names', None)  # Usunięcie listy nazw akcelerometru\n",
        "    data.pop('gyro_names', None)  # Usunięcie listy nazw żyroskopu\n",
        "    data.pop('ecg_names', None)  # Usunięcie listy nazw EKG\n",
        "    return data\n",
        "        \n",
        " \n",
        "# data = load_cardiac_patient_data('Raw_Recordings/UP-25-Raw.csv')\n",
        "# for key in data.keys():\n",
        "#     print(f\"{key}: {data[key].shape if isinstance(data[key], np.ndarray) else data[key]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Implementacja Detektorów Tętna\n",
        "\n",
        "Implementujemy detektory dla różnych modalności:\n",
        "- **EKG**: Klasyczny detektor zespołów QRS\n",
        "- **SCG** (Sejsmokardiografia): Detektor na podstawie akcelerometru\n",
        "- **GCG** (Żyrokardiografia): Detektor na podstawie żyroskopu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HeartbeatDetector:\n",
        "    \"\"\"Klasa bazowa dla detektorów tętna\"\"\"\n",
        "    \n",
        "    def __init__(self, fs):\n",
        "        self.fs = fs\n",
        "    \n",
        "    def bandpass_filter(self, signal, low_freq, high_freq, order=4):\n",
        "        \"\"\"Filtr pasmowo-przepustowy\"\"\"\n",
        "        nyquist = self.fs / 2\n",
        "        low = low_freq / nyquist\n",
        "        high = high_freq / nyquist\n",
        "        b, a = butter(order, [low, high], btype='band')\n",
        "        return filtfilt(b, a, signal)\n",
        "    \n",
        "    def detect_peaks(self, signal, **kwargs):\n",
        "        \"\"\"Bazowa metoda detekcji pików\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ECGDetector(HeartbeatDetector):\n",
        "    \"\"\"Detektor dla sygnałów EKG - Pan-Tompkins algorithm\"\"\"\n",
        "    \n",
        "    def detect_peaks(self, ecg_signal, min_peak_height=None, min_distance=None):\n",
        "        \"\"\"Detekcja zespołów QRS w sygnale EKG\"\"\"\n",
        "        \n",
        "        # Parametry domyślne\n",
        "        if min_distance is None:\n",
        "            min_distance = int(0.6 * self.fs)  # Minimum 100 BPM\n",
        "        \n",
        "        # Krok 1: Filtracja pasmowa (5-15 Hz dla QRS)\n",
        "        filtered = self.bandpass_filter(ecg_signal, 5, 15)\n",
        "        \n",
        "        # Krok 2: Różniczkowanie\n",
        "        diff_signal = np.diff(filtered)\n",
        "        \n",
        "        # Krok 3: Podnoszenie do kwadratu\n",
        "        squared = diff_signal ** 2\n",
        "        \n",
        "        # Krok 4: Średnia ruchoma\n",
        "        window_size = int(0.15 * self.fs)  # 150ms window\n",
        "        integrated = np.convolve(squared, np.ones(window_size)/window_size, mode='same')\n",
        "        \n",
        "        # Krok 5: Detekcja pików\n",
        "        if min_peak_height is None:\n",
        "            min_peak_height = 0.35 * np.max(integrated)\n",
        "        \n",
        "        peaks, _ = find_peaks(integrated, \n",
        "                            height=min_peak_height,\n",
        "                            distance=min_distance)\n",
        "        \n",
        "        return peaks\n",
        "\n",
        "class SCGDetector(HeartbeatDetector):\n",
        "    \"\"\"Detektor dla sejsmokardiogramów (akcelerometr)\"\"\"\n",
        "    \n",
        "    def detect_peaks(self, acc_signal, axis=2, min_peak_height=None, min_distance=None):\n",
        "        \"\"\"Detekcja uderzeń serca z sygnału akcelerometru\"\"\"\n",
        "        \n",
        "        if min_distance is None:\n",
        "            min_distance = int(0.4 * self.fs)  # Minimum 150 BPM\n",
        "        \n",
        "        # Wybierz odpowiednią oś lub oblicz magnitude\n",
        "        if acc_signal.ndim == 1:\n",
        "            signal_to_process = acc_signal\n",
        "        else:\n",
        "            if axis is None:\n",
        "                # Magnitude wszystkich osi\n",
        "                signal_to_process = np.sqrt(np.sum(acc_signal**2, axis=1))\n",
        "            else:\n",
        "                signal_to_process = acc_signal[:, axis]\n",
        "        \n",
        "        # Filtracja dla sygnałów kardiologicznych (1-40 Hz)\n",
        "        filtered = self.bandpass_filter(signal_to_process, 1, 40)\n",
        "        \n",
        "        # Wzmocnienie przez podniesienie do kwadratu\n",
        "        enhanced = filtered ** 2\n",
        "        \n",
        "        # Wygładzenie\n",
        "        window_size = int(0.1 * self.fs)  # 100ms window\n",
        "        smoothed = np.convolve(enhanced, np.ones(window_size)/window_size, mode='same')\n",
        "        \n",
        "        # Detekcja pików\n",
        "        if min_peak_height is None:\n",
        "            min_peak_height = 0.3 * np.max(smoothed)\n",
        "        \n",
        "        peaks, _ = find_peaks(smoothed,\n",
        "                            height=min_peak_height,\n",
        "                            distance=min_distance)\n",
        "        \n",
        "        return peaks\n",
        "\n",
        "class GCGDetector(HeartbeatDetector):\n",
        "    \"\"\"Detektor dla żyrokardiogramów (żyroskop)\"\"\"\n",
        "    \n",
        "    def detect_peaks(self, gyro_signal, axis=2, min_peak_height=None, min_distance=None):\n",
        "        \"\"\"Detekcja uderzeń serca z sygnału żyroskopu\"\"\"\n",
        "        \n",
        "        if min_distance is None:\n",
        "            min_distance = int(0.4 * self.fs)  # Minimum 150 BPM\n",
        "        \n",
        "        # Wybierz odpowiednią oś lub oblicz magnitude\n",
        "        if gyro_signal.ndim == 1:\n",
        "            signal_to_process = gyro_signal\n",
        "        else:\n",
        "            if axis is None:\n",
        "                # Magnitude wszystkich osi\n",
        "                signal_to_process = np.sqrt(np.sum(gyro_signal**2, axis=1))\n",
        "            else:\n",
        "                signal_to_process = gyro_signal[:, axis]\n",
        "        \n",
        "        # Filtracja dla sygnałów kardiologicznych (1-20 Hz)\n",
        "        filtered = self.bandpass_filter(signal_to_process, 1, 20)\n",
        "        \n",
        "        # Wartość bezwzględna różniczki (wykrywa szybkie zmiany)\n",
        "        diff_signal = np.abs(np.diff(filtered))\n",
        "        diff_signal = np.append(diff_signal, diff_signal[-1])  # Restore length\n",
        "        \n",
        "        # Wygładzenie\n",
        "        window_size = int(0.08 * self.fs)  # 80ms window\n",
        "        smoothed = np.convolve(diff_signal, np.ones(window_size)/window_size, mode='same')\n",
        "        \n",
        "        # Detekcja pików\n",
        "        if min_peak_height is None:\n",
        "            min_peak_height = 0.4 * np.max(smoothed)\n",
        "        \n",
        "        peaks, _ = find_peaks(smoothed,\n",
        "                            height=min_peak_height,\n",
        "                            distance=min_distance)\n",
        "        \n",
        "        return peaks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Analiza HRV (Heart Rate Variability)\n",
        "\n",
        "Implementujemy analizę zmienności rytmu serca w trzech domenach:\n",
        "- **Dziedzina czasu**: AVNN, SDNN, RMSSD, pNN50\n",
        "- **Dziedzina częstotliwości**: VLF, LF, HF, LF/HF\n",
        "- **Analiza nieliniowa**: wykres Poincaré (SD1, SD2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HRVAnalyzer:\n",
        "    \"\"\"Klasa do analizy zmienności rytmu serca\"\"\"\n",
        "    \n",
        "    def __init__(self, rr_intervals):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            rr_intervals: odstępy RR w milisekundach\n",
        "        \"\"\"\n",
        "        self.rr_intervals = np.array(rr_intervals)\n",
        "        self.nn_intervals = self.filter_normal_intervals()  # Filtrowane odstępy NN\n",
        "    \n",
        "    def filter_normal_intervals(self, min_rr=300, max_rr=2000):\n",
        "        \"\"\"Filtracja nietypowych odstępów RR\"\"\"\n",
        "        mask = (self.rr_intervals >= min_rr) & (self.rr_intervals <= max_rr)\n",
        "        return self.rr_intervals[mask]\n",
        "    \n",
        "    def time_domain_analysis(self):\n",
        "        \"\"\"Analiza w dziedzinie czasu\"\"\"\n",
        "        if len(self.nn_intervals) < 2:\n",
        "            return {}\n",
        "        \n",
        "        # Podstawowe statystyki\n",
        "        avnn = np.mean(self.nn_intervals)  # Średni odstęp NN\n",
        "        sdnn = np.std(self.nn_intervals, ddof=1)  # Odchylenie standardowe\n",
        "        \n",
        "        # RMSSD - Root Mean Square of Successive Differences\n",
        "        diff_nn = np.diff(self.nn_intervals)\n",
        "        rmssd = np.sqrt(np.mean(diff_nn**2))\n",
        "        \n",
        "        # pNN50 - procent różnic > 50ms\n",
        "        pnn50 = (np.sum(np.abs(diff_nn) > 50) / len(diff_nn)) * 100\n",
        "        \n",
        "        # pNN20 - procent różnic > 20ms (dodatkowy wskaźnik)\n",
        "        pnn20 = (np.sum(np.abs(diff_nn) > 20) / len(diff_nn)) * 100\n",
        "        \n",
        "        return {\n",
        "            'AVNN': avnn,\n",
        "            'SDNN': sdnn,\n",
        "            'RMSSD': rmssd,\n",
        "            'pNN50': pnn50,\n",
        "            'pNN20': pnn20,\n",
        "            'HR_mean': 60000 / avnn if avnn > 0 else 0  # Średnie tętno\n",
        "        }\n",
        "    \n",
        "    def frequency_domain_analysis(self, fs_resample=4):\n",
        "        \"\"\"Analiza w dziedzinie częstotliwości\"\"\"\n",
        "        if len(self.nn_intervals) < 10:\n",
        "            return {}\n",
        "        \n",
        "        # Interpolacja do równomiernie próbkowanego sygnału\n",
        "        time_original = np.cumsum(self.nn_intervals) / 1000.0  # Convert to seconds\n",
        "        time_new = np.arange(0, time_original[-1], 1/fs_resample)\n",
        "        \n",
        "        # Interpolacja liniowa\n",
        "        rr_interpolated = np.interp(time_new, time_original, self.nn_intervals)\n",
        "        \n",
        "        # Detrending\n",
        "        rr_detrended = rr_interpolated - np.mean(rr_interpolated)\n",
        "        \n",
        "        # FFT\n",
        "        fft_vals = np.fft.fft(rr_detrended)\n",
        "        fft_freqs = np.fft.fftfreq(len(rr_detrended), 1/fs_resample)\n",
        "        \n",
        "        # Power spectral density (PSD)\n",
        "        psd = np.abs(fft_vals)**2\n",
        "        \n",
        "        # Definicje pasm częstotliwości (Hz)\n",
        "        vlf_band = (0.0033, 0.04)\n",
        "        lf_band = (0.04, 0.15)\n",
        "        hf_band = (0.15, 0.4)\n",
        "        \n",
        "        # Znajdź indeksy dla każdego pasma\n",
        "        def get_band_power(freq_range):\n",
        "            mask = (fft_freqs >= freq_range[0]) & (fft_freqs <= freq_range[1])\n",
        "            return np.sum(psd[mask]) if np.any(mask) else 0\n",
        "        \n",
        "        vlf_power = get_band_power(vlf_band)\n",
        "        lf_power = get_band_power(lf_band)\n",
        "        hf_power = get_band_power(hf_band)\n",
        "        \n",
        "        total_power = vlf_power + lf_power + hf_power\n",
        "        \n",
        "        # Znormalizowane moce\n",
        "        lf_norm = (lf_power / (lf_power + hf_power)) * 100 if (lf_power + hf_power) > 0 else 0\n",
        "        hf_norm = (hf_power / (lf_power + hf_power)) * 100 if (lf_power + hf_power) > 0 else 0\n",
        "        \n",
        "        # Stosunek LF/HF\n",
        "        lf_hf_ratio = lf_power / hf_power if hf_power > 0 else 0\n",
        "        \n",
        "        return {\n",
        "            'VLF_power': vlf_power,\n",
        "            'LF_power': lf_power,\n",
        "            'HF_power': hf_power,\n",
        "            'Total_power': total_power,\n",
        "            'LF_norm': lf_norm,\n",
        "            'HF_norm': hf_norm,\n",
        "            'LF_HF_ratio': lf_hf_ratio\n",
        "        }\n",
        "    \n",
        "    def nonlinear_analysis(self):\n",
        "        \"\"\"Analiza nieliniowa - wykres Poincaré\"\"\"\n",
        "        if len(self.nn_intervals) < 2:\n",
        "            return {}\n",
        "        \n",
        "        # Współrzędne wykresu Poincaré\n",
        "        rr_n = self.nn_intervals[:-1]\n",
        "        rr_n1 = self.nn_intervals[1:]\n",
        "        \n",
        "        # SD1 - krótkookresowa zmienność (szerokość chmury punktów)\n",
        "        diff_rr = rr_n1 - rr_n\n",
        "        sd1 = np.std(diff_rr, ddof=1) / np.sqrt(2)\n",
        "        \n",
        "        # SD2 - długookresowa zmienność (długość chmury punktów)\n",
        "        sum_rr = rr_n1 + rr_n\n",
        "        sd2 = np.std(sum_rr, ddof=1) / np.sqrt(2)\n",
        "        \n",
        "        # SD1/SD2 ratio\n",
        "        sd_ratio = sd1 / sd2 if sd2 > 0 else 0\n",
        "        \n",
        "        return {\n",
        "            'SD1': sd1,\n",
        "            'SD2': sd2,\n",
        "            'SD1_SD2_ratio': sd_ratio,\n",
        "            'poincare_rr_n': rr_n,\n",
        "            'poincare_rr_n1': rr_n1\n",
        "        }\n",
        "    \n",
        "    def comprehensive_analysis(self):\n",
        "        \"\"\"Kompletna analiza HRV\"\"\"\n",
        "        results = {}\n",
        "        results.update(self.time_domain_analysis())\n",
        "        results.update(self.frequency_domain_analysis())\n",
        "        results.update(self.nonlinear_analysis())\n",
        "        return results\n",
        "\n",
        "def peaks_to_rr_intervals(peaks, fs):\n",
        "    \"\"\"Konwersja pozycji pików na odstępy RR w milisekundach\"\"\"\n",
        "    if len(peaks) < 2:\n",
        "        return np.array([])\n",
        "    \n",
        "    rr_samples = np.diff(peaks)\n",
        "    rr_ms = (rr_samples / fs) * 1000  # Convert to milliseconds\n",
        "    return rr_ms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Przykład Analizy Multimodalnej\n",
        "\n",
        "Teraz przeprowadzimy przykładową analizę na rzeczywistych danych z obu datasetów.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Błąd podczas analizy: too many indices for array: array is 1-dimensional, but 2 were indexed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_63671/3618820127.py\", line 6, in multimodal_analysis_example\n",
            "    patient_data = load_cardiac_patient_data('Raw_Recordings/CP-01-Raw.csv')\n",
            "  File \"/tmp/ipykernel_63671/101613974.py\", line 85, in load_cardiac_patient_data\n",
            "    data['ecg'] = data['ecg'][:, i]\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n"
          ]
        }
      ],
      "source": [
        "def multimodal_analysis_example():\n",
        "    \"\"\"Przykład analizy multimodalnej dla jednego pacjenta\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Załaduj dane pacjenta\n",
        "        patient_data = load_cardiac_patient_data('Raw_Recordings/CP-01-Raw.csv')\n",
        "        \n",
        "        if patient_data is None:\n",
        "            print(\"Nie udało się załadować danych pacjenta\")\n",
        "            return\n",
        "        \n",
        "        fs = patient_data['fs']\n",
        "        duration_minutes = patient_data['time'][-1] / 60\n",
        "        \n",
        "        print(f\"=== Analiza Pacjenta CP-01 ===\")\n",
        "        print(f\"Czas nagrania: {duration_minutes:.1f} minut\")\n",
        "        print(f\"Częstotliwość próbkowania: {fs:.1f} Hz\")\n",
        "        print()\n",
        "        \n",
        "        # Wybierz fragment danych (np. pierwsze 5 minut)\n",
        "        max_samples = int(5 * 60 * fs)  # 5 minut\n",
        "        end_idx = min(max_samples, len(patient_data['time']))\n",
        "        \n",
        "        # === ANALIZA EKG ===\n",
        "        if 'ecg' in patient_data:\n",
        "            print(\"--- Analiza EKG ---\")\n",
        "            # Użyj pierwszego odprowadzenia EKG\n",
        "            ecg_signal = patient_data['ecg'][:end_idx]\n",
        "            \n",
        "            # Detekcja QRS\n",
        "            ecg_detector = ECGDetector(fs)\n",
        "            qrs_peaks = ecg_detector.detect_peaks(ecg_signal)\n",
        "            \n",
        "            if len(qrs_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals = peaks_to_rr_intervals(qrs_peaks, fs)\n",
        "                hrv_analyzer = HRVAnalyzer(rr_intervals)\n",
        "                hrv_results_ecg = hrv_analyzer.comprehensive_analysis()\n",
        "                \n",
        "                print(f\"Wykryto {len(qrs_peaks)} zespołów QRS\")\n",
        "                print(f\"Średnie tętno: {hrv_results_ecg.get('HR_mean', 0):.1f} BPM\")\n",
        "                print(f\"SDNN: {hrv_results_ecg.get('SDNN', 0):.1f} ms\")\n",
        "                print(f\"RMSSD: {hrv_results_ecg.get('RMSSD', 0):.1f} ms\")\n",
        "                print(f\"LF/HF: {hrv_results_ecg.get('LF_HF_ratio', 0):.2f}\")\n",
        "            else:\n",
        "                print(\"Nie wykryto wystarczającej liczby zespołów QRS\")\n",
        "                hrv_results_ecg = {}\n",
        "\n",
        "        # === ANALIZA AKCELEROMETRU ===\n",
        "        if 'accZ' in patient_data:\n",
        "            print(\"\\n--- Analiza Akcelerometru ---\")\n",
        "            # Użyj osi Z akcelerometru\n",
        "            acc_signal = patient_data['accZ'][:end_idx] # Z-axis\n",
        "            \n",
        "            # Detekcja uderzeń serca\n",
        "            scg_detector = SCGDetector(fs)\n",
        "            scg_peaks = scg_detector.detect_peaks(acc_signal, axis=None)  # Single axis\n",
        "            \n",
        "            if len(scg_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals_scg = peaks_to_rr_intervals(scg_peaks, fs)\n",
        "                hrv_analyzer_scg = HRVAnalyzer(rr_intervals_scg)\n",
        "                hrv_results_scg = hrv_analyzer_scg.comprehensive_analysis()\n",
        "                \n",
        "                print(f\"Wykryto {len(scg_peaks)} uderzeń serca (SCG)\")\n",
        "                print(f\"Średnie tętno: {hrv_results_scg.get('HR_mean', 0):.1f} BPM\")\n",
        "                print(f\"SDNN: {hrv_results_scg.get('SDNN', 0):.1f} ms\")\n",
        "                print(f\"RMSSD: {hrv_results_scg.get('RMSSD', 0):.1f} ms\")\n",
        "                print(f\"LF/HF: {hrv_results_scg.get('LF_HF_ratio', 0):.2f}\")\n",
        "            else:\n",
        "                print(\"Nie wykryto wystarczającej liczby uderzeń serca (SCG)\")\n",
        "                hrv_results_scg = {}\n",
        "        \n",
        "        # === ANALIZA ŻYROSKOPU ===\n",
        "        if 'gyroZ' in patient_data:\n",
        "            print(\"\\n--- Analiza Żyroskopu ---\")\n",
        "            # Użyj osi Z żyroskopu\n",
        "            gyro_signal = patient_data['gyroZ'][:end_idx]  # Z-axis\n",
        "            \n",
        "            # Detekcja uderzeń serca\n",
        "            gcg_detector = GCGDetector(fs)\n",
        "            gcg_peaks = gcg_detector.detect_peaks(gyro_signal, axis=None)  # Single axis\n",
        "            \n",
        "            if len(gcg_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals_gcg = peaks_to_rr_intervals(gcg_peaks, fs)\n",
        "                hrv_analyzer_gcg = HRVAnalyzer(rr_intervals_gcg)\n",
        "                hrv_results_gcg = hrv_analyzer_gcg.comprehensive_analysis()\n",
        "                \n",
        "                print(f\"Wykryto {len(gcg_peaks)} uderzeń serca (GCG)\")\n",
        "                print(f\"Średnie tętno: {hrv_results_gcg.get('HR_mean', 0):.1f} BPM\")\n",
        "                print(f\"SDNN: {hrv_results_gcg.get('SDNN', 0):.1f} ms\")\n",
        "                print(f\"RMSSD: {hrv_results_gcg.get('RMSSD', 0):.1f} ms\")\n",
        "                print(f\"LF/HF: {hrv_results_gcg.get('LF_HF_ratio', 0):.2f}\")\n",
        "            else:\n",
        "                print(\"Nie wykryto wystarczającej liczby uderzeń serca (GCG)\")\n",
        "                hrv_results_gcg = {}\n",
        "        \n",
        "        print(\"\\n=== Analiza zakończona ===\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Błąd podczas analizy: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "multimodal_analysis_example()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Pozyskanie Danych wszystkich deskrytporów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_descriptors(patient_data):\n",
        "    result = {'ecg_pulse': 0.0,\n",
        "              'ecg_sdnn': 0.0,\n",
        "              'ecg_rmssd': 0.0,\n",
        "              'ecg_lf_hf': 0.0,\n",
        "              'accX_pulse': 0.0,\n",
        "              'accX_sdnn': 0.0,\n",
        "              'accX_rmssd': 0.0,\n",
        "              'accX_lf_hf': 0.0,\n",
        "              'accY_pulse': 0.0,\n",
        "              'accY_sdnn': 0.0,\n",
        "              'accY_rmssd': 0.0,\n",
        "              'accY_lf_hf': 0.0,\n",
        "              'accZ_pulse': 0.0,\n",
        "              'accZ_sdnn': 0.0,\n",
        "              'accZ_rmssd': 0.0,\n",
        "              'accZ_lf_hf': 0.0,\n",
        "              'gyroX_pulse': 0.0,\n",
        "              'gyroX_sdnn': 0.0,\n",
        "              'gyroX_rmssd': 0.0,\n",
        "              'gyroX_lf_hf': 0.0,\n",
        "              'gyroY_pulse': 0.0,\n",
        "              'gyroY_sdnn': 0.0,\n",
        "              'gyroY_rmssd': 0.0,\n",
        "              'gyroY_lf_hf': 0.0,\n",
        "              'gyroZ_pulse': 0.0,\n",
        "              'gyroZ_sdnn': 0.0,\n",
        "              'gyroZ_rmssd': 0.0,\n",
        "              'gyroZ_lf_hf': 0.0}\n",
        "\n",
        "    if patient_data is None or 'fs' not in patient_data or 'time' not in patient_data:\n",
        "        print(\"Nieprawidłowe dane pacjenta lub brak wymaganych kluczy.\")\n",
        "        return result\n",
        "    fs = patient_data['fs']\n",
        "    duration_minutes = patient_data['time'][-1] / 60\n",
        "    max_samples = int(duration_minutes * 60 * fs)  # 2 minut wiekszosc danych jest tej dlugosci\n",
        "    end_idx = len(patient_data['time'])\n",
        "\n",
        "    if 'ecg' in patient_data:\n",
        "        ecg_signal = patient_data['ecg'][:end_idx]\n",
        "        \n",
        "        # Detekcja QRS\n",
        "        ecg_detector = ECGDetector(fs)\n",
        "        qrs_peaks = ecg_detector.detect_peaks(ecg_signal)\n",
        "        \n",
        "        if len(qrs_peaks) > 1:\n",
        "            # Analiza HRV\n",
        "            rr_intervals = peaks_to_rr_intervals(qrs_peaks, fs)\n",
        "            hrv_analyzer = HRVAnalyzer(rr_intervals)\n",
        "            hrv_results_ecg = hrv_analyzer.comprehensive_analysis()\n",
        "\n",
        "            result['ecg_pulse'] = hrv_results_ecg.get('HR_mean', 0)\n",
        "            result['ecg_sdnn'] = hrv_results_ecg.get('SDNN', 0)\n",
        "            result['ecg_rmssd'] = hrv_results_ecg.get('RMSSD', 0)\n",
        "            result['ecg_lf_hf'] = hrv_results_ecg.get('LF_HF_ratio', 0)\n",
        "\n",
        "    for acc in ['accX', 'accY', 'accZ']:\n",
        "        if acc in patient_data:\n",
        "            acc_signal = patient_data[acc][:end_idx] \n",
        "            \n",
        "            # Detekcja uderzeń serca\n",
        "            scg_detector = SCGDetector(fs)\n",
        "            scg_peaks = scg_detector.detect_peaks(acc_signal, axis=None)  # Single axis\n",
        "            \n",
        "            if len(scg_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals_scg = peaks_to_rr_intervals(scg_peaks, fs)\n",
        "                hrv_analyzer_scg = HRVAnalyzer(rr_intervals_scg)\n",
        "                hrv_results_scg = hrv_analyzer_scg.comprehensive_analysis()\n",
        "\n",
        "                result[f'{acc}_pulse'] = hrv_results_scg.get('HR_mean', 0)\n",
        "                result[f'{acc}_sdnn'] = hrv_results_scg.get('SDNN', 0)\n",
        "                result[f'{acc}_rmssd'] = hrv_results_scg.get('RMSSD', 0)\n",
        "                result[f'{acc}_lf_hf'] = hrv_results_scg.get('LF_HF_ratio', 0)\n",
        "    for gyro in ['gyroX', 'gyroY', 'gyroZ']:\n",
        "        if gyro in patient_data:\n",
        "            gyro_signal = patient_data[gyro][:end_idx]  \n",
        "            \n",
        "            # Detekcja uderzeń serca\n",
        "            gcg_detector = GCGDetector(fs)\n",
        "            gcg_peaks = gcg_detector.detect_peaks(gyro_signal, axis=None)\n",
        "            if len(gcg_peaks) > 1:\n",
        "                # Analiza HRV\n",
        "                rr_intervals_gcg = peaks_to_rr_intervals(gcg_peaks, fs)\n",
        "                hrv_analyzer_gcg = HRVAnalyzer(rr_intervals_gcg)\n",
        "                hrv_results_gcg = hrv_analyzer_gcg.comprehensive_analysis()\n",
        "\n",
        "                result[f'{gyro}_pulse'] = hrv_results_gcg.get('HR_mean', 0)\n",
        "                result[f'{gyro}_sdnn'] = hrv_results_gcg.get('SDNN', 0)\n",
        "                result[f'{gyro}_rmssd'] = hrv_results_gcg.get('RMSSD', 0)\n",
        "                result[f'{gyro}_lf_hf'] = hrv_results_gcg.get('LF_HF_ratio', 0)\n",
        "    return result\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Przetwarzanie pliku: sub_10.txt\n",
            "Przetwarzanie pliku: sub_8.txt\n",
            "Przetwarzanie pliku: sub_18.txt\n",
            "Przetwarzanie pliku: sub_14.txt\n",
            "Przetwarzanie pliku: sub_2.txt\n",
            "Przetwarzanie pliku: sub_11.txt\n",
            "Przetwarzanie pliku: sub_22.txt\n",
            "Przetwarzanie pliku: sub_21.txt\n",
            "Przetwarzanie pliku: sub_16.txt\n",
            "Przetwarzanie pliku: sub_15.txt\n",
            "Przetwarzanie pliku: sub_24.txt\n",
            "Przetwarzanie pliku: sub_12.txt\n",
            "Przetwarzanie pliku: sub_28.txt\n",
            "Przetwarzanie pliku: sub_3.txt\n",
            "Przetwarzanie pliku: sub_20.txt\n",
            "Przetwarzanie pliku: sub_4.txt\n",
            "Przetwarzanie pliku: sub_9.txt\n",
            "Przetwarzanie pliku: sub_7.txt\n",
            "Przetwarzanie pliku: sub_6.txt\n",
            "Przetwarzanie pliku: sub_17.txt\n",
            "Przetwarzanie pliku: sub_23.txt\n",
            "Przetwarzanie pliku: sub_29.txt\n",
            "Przetwarzanie pliku: sub_25.txt\n",
            "Przetwarzanie pliku: sub_27.txt\n",
            "Przetwarzanie pliku: sub_19.txt\n",
            "Przetwarzanie pliku: sub_13.txt\n",
            "Przetwarzanie pliku: sub_26.txt\n",
            "Przetwarzanie pliku: sub_5.txt\n",
            "Przetwarzanie pliku: sub_1.txt\n",
            "Przetwarzanie pliku: CP-26-Raw.csv\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(sick_directpor):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrzetwarzanie pliku: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mload_cardiac_patient_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msick_directpor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         descriptors \u001b[38;5;241m=\u001b[39m get_descriptors(data)\n",
            "Cell \u001b[0;32mIn[28], line 85\u001b[0m, in \u001b[0;36mload_cardiac_patient_data\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecg_names\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m24BIT\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecg_names\u001b[39m\u001b[38;5;124m'\u001b[39m][i]:\n\u001b[0;32m---> 85\u001b[0m         data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mecg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# ECG_ECG_LA-RA_24BIT_CAL\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# data['ecg'] = data['ecg'][:, 0] if 'ecg' in data else None  # Użyj tylko pierwszej kolumny EKG TODO: check bo to chyba status???\u001b[39;00m\n\u001b[1;32m     91\u001b[0m data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerometer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Usunięcie surowych danych akcelerometru\u001b[39;00m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ],
      "source": [
        "#load all data\n",
        "import os\n",
        "healthy_directpor = 'Surowe'\n",
        "sick_directpor = 'Raw_Recordings'\n",
        "df = pd.DataFrame()\n",
        "for filename in os.listdir(healthy_directpor):\n",
        "    print(f\"Przetwarzanie pliku: {filename}\")\n",
        "    data = load_mechanocardiogram(os.path.join(healthy_directpor, filename))\n",
        "    descriptors = get_descriptors(data)\n",
        "    descriptors['sick'] = 0\n",
        "    #save descriptors to csv\n",
        "    df = pd.concat([df, pd.DataFrame([descriptors])], ignore_index=True)\n",
        "\n",
        "for filename in os.listdir(sick_directpor):\n",
        "    print(f\"Przetwarzanie pliku: {filename}\")\n",
        "    data = load_cardiac_patient_data(os.path.join(sick_directpor, filename))\n",
        "    if data is not None:\n",
        "        descriptors = get_descriptors(data)\n",
        "        descriptors['sick'] = 1\n",
        "        #save descriptors to csv\n",
        "        df = pd.concat([df, pd.DataFrame([descriptors])], ignore_index=True)\n",
        "# Save the descriptors to a CSV file\n",
        "df.to_csv('descriptors.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
